{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "local autograd = require 'autograd'\n",
    "\n",
    "local input_size = 2\n",
    "local hidden_size = 3\n",
    "local output_size = 2\n",
    "\n",
    "local model = nn.Sequential()                                                            \n",
    "   model:add(nn.Linear(input_size, hidden_size))                                         \n",
    "   model:add(nn.Sigmoid())                                                               \n",
    "--   model:add(nn.Linear(hidden_size, hidden_size))                                      \n",
    "--   model:add(nn.Sigmoid())                                                             \n",
    "   model:add(nn.Linear(hidden_size, hidden_size))                                        \n",
    "   model:add(nn.Sigmoid())                                                               \n",
    "   model:add(nn.Linear(hidden_size, output_size))                                        \n",
    "   model:add(nn.LogSoftMax())                                                            \n",
    "--local criterion = nn.MSECriterion()   \n",
    "local criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "modelf, params = autograd.functionalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params2 = { W = {}, b = {}}\n",
    "params2[\"W\"][1] = params[1]:t()\n",
    "params2[\"b\"][1] = params[2]\n",
    "params2[\"W\"][2] = params[3]\n",
    "params2[\"b\"][2] = params[4]\n",
    "params2[\"W\"][3] = params[5]\n",
    "params2[\"b\"][3] = params[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  b : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 3\n",
       "      2 : DoubleTensor - size: 3\n",
       "      3 : DoubleTensor - size: 2\n",
       "    }\n",
       "  W : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 2x3\n",
       "      2 : DoubleTensor - size: 3x3\n",
       "      3 : DoubleTensor - size: 2x3\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params2[\"W\"]['1'] = params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2376  0.2593  1.0499 -1.9854  0.4596 -0.4945 -0.9845  0.3219 -1.8773 -0.4227\n",
       " 0.8345  0.6762 -0.5234 -0.4173 -0.3695  0.1877  1.1133 -1.1186 -0.4645 -0.4989\n",
       "-0.1898  0.0146  2.2595  1.4802  1.2333 -0.2303 -0.9503 -0.4051  0.3107  1.1381\n",
       " 0.0776  0.7438  2.0996 -1.7159 -0.6524 -0.4740  0.3326 -0.8217 -0.4886 -1.7005\n",
       " 1.5302 -0.9161 -2.1216  1.3817 -0.2140  0.3005 -1.2715 -0.6862 -0.0874  0.0757\n",
       "-0.8222 -0.3303 -1.6569  0.6664  0.4702  0.8818  1.5320  0.6318 -0.3984  0.8268\n",
       " 2.9777  2.2614  0.6985 -1.3137 -0.8751 -0.2908 -0.3094  0.6281  0.8190 -1.6872\n",
       "-1.7495  0.7034 -0.4442 -0.1337  0.9605 -0.8278 -0.7095 -0.4473 -0.3967 -0.0739\n",
       "-0.5814 -1.3168  0.8787  0.9828  1.1744 -1.2145 -1.7715  1.5070 -0.8834  0.9917\n",
       " 1.0851  0.3650 -0.1027 -0.4596 -1.6443  0.3173  1.0060 -0.5341  0.4793 -0.9573\n",
       "[torch.DoubleTensor of size 10x10]\n",
       "\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local input_size = 10 \n",
    "local target_size = 10 \n",
    "local hidden_size = 10\n",
    "local mini_batch_size = 10\n",
    "\n",
    "local input = torch.randn(mini_batch_size, input_size)\n",
    "local target = torch.ceil(torch.rand(mini_batch_size)*target_size)\n",
    "\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.4843  0.9823\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local input_size = 2\n",
    "local output_size = 2   \n",
    "local input = torch.randn(1,input_size)\n",
    "local target = torch.Tensor(1,output_size):zero() \n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
