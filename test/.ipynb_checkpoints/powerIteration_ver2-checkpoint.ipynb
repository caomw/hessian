{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mnist> done\t\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000\t\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-2.0779814142286e-12\t\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0000000001234\t\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'dataset-mnist'\n",
    "\n",
    "-- geometry: width and height of input images\n",
    "geometry = {32,32}\n",
    "numChannels = 1\n",
    "\n",
    "nbTestingPatches = 10000\n",
    "\n",
    "-- load test set\n",
    "testData = mnist.loadTestSet(nbTestingPatches, geometry)\n",
    "labels = torch.Tensor(nbTestingPatches)\n",
    "for i = 1,nbTestingPatches do\n",
    "     local sample = testData[i]\n",
    "     local _,target = sample[2]:clone():max(1)\n",
    "     target = target:squeeze()\n",
    "     labels[i] = target\n",
    "end\n",
    "\n",
    "-- do global normalization\n",
    "testData:normalizeGlobal()\n",
    "\n",
    "\n",
    "print(testData:size())\n",
    "print(testData.data:mean())\n",
    "print(testData.data:std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "--modelpath = \"reduced-train-mnist-model.lua\"\n",
    "--local model = nn.Sequential()\n",
    "--model:add(dofile(modelpath))\n",
    "model1 = torch.load('mnist.baseline.net.final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> output]\n",
       "  (1): nn.SpatialConvolutionMM(1 -> 32, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(3,3,3,3)\n",
       "  (4): nn.SpatialConvolutionMM(32 -> 64, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (7): nn.Reshape(256)\n",
       "  (8): nn.Linear(256 -> 200)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(200 -> 10)\n",
       "  (11): nn.LogSoftMax\n",
       "}\n",
       "{\n",
       "  gradInput : DoubleTensor - size: 100x1x32x32\n",
       "  modules : \n",
       "    {\n",
       "      1 : \n",
       "        nn.SpatialConvolutionMM(1 -> 32, 5x5)\n",
       "        {\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 32\n",
       "          output : DoubleTensor - size: 100x32x28x28\n",
       "          gradInput : DoubleTensor - size: 100x1x32x32\n",
       "          kW : 5\n",
       "          finput : DoubleTensor - size: 100x25x784\n",
       "          kH : 5\n",
       "          nInputPlane : 1\n",
       "          weight : DoubleTensor - size: 32x25\n",
       "          padW : 0\n",
       "          gradWeight : DoubleTensor - size: 32x25\n",
       "          bias : DoubleTensor - size: 32\n",
       "          padH : 0\n",
       "          gradBias : DoubleTensor - size: 32\n",
       "          fgradInput : DoubleTensor - size: 100x25x784\n",
       "        }\n",
       "      2 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - size: 100x32x28x28\n",
       "          gradInput : DoubleTensor - size: 100x32x28x28\n",
       "        }\n",
       "      3 : \n",
       "        nn.SpatialMaxPooling(3,3,3,3)\n",
       "        {\n",
       "          dH : 3\n",
       "          dW : 3\n",
       "          output : DoubleTensor - size: 100x32x9x9\n",
       "          kH : 3\n",
       "          indices : DoubleTensor - size: 100x32x9x9\n",
       "          padW : 0\n",
       "          ceil_mode : false\n",
       "          kW : 3\n",
       "          padH : 0\n",
       "          gradInput : DoubleTensor - size: 100x32x28x28\n",
       "        }\n",
       "      4 : \n",
       "        nn.SpatialConvolutionMM(32 -> 64, 5x5)\n",
       "        {\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 64\n",
       "          output : DoubleTensor - size: 100x64x5x5\n",
       "          gradInput : DoubleTensor - size: 100x32x9x9\n",
       "          kW : 5\n",
       "          finput : DoubleTensor - size: 100x800x25\n",
       "          kH : 5\n",
       "          nInputPlane : 32\n",
       "          weight : DoubleTensor - size: 64x800\n",
       "          padW : 0\n",
       "          gradWeight : DoubleTensor - size: 64x800\n",
       "          bias : DoubleTensor - size: 64\n",
       "          padH : 0\n",
       "          gradBias : DoubleTensor - size: 64\n",
       "          fgradInput : DoubleTensor - size: 100x800x25\n",
       "        }\n",
       "      5 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - size: 100x64x5x5\n",
       "          gradInput : DoubleTensor - size: 100x64x5x5\n",
       "        }\n",
       "      6 : \n",
       "        nn.SpatialMaxPooling(2,2,2,2)\n",
       "        {"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "          dH : 2\n",
       "          dW : 2\n",
       "          output : DoubleTensor - size: 100x64x2x2\n",
       "          kH : 2\n",
       "          indices : DoubleTensor - size: 100x64x2x2\n",
       "          padW : 0\n",
       "          ceil_mode : false\n",
       "          kW : 2\n",
       "          padH : 0\n",
       "          gradInput : DoubleTensor - size: 100x64x5x5\n",
       "        }\n",
       "      7 : \n",
       "        nn.Reshape(256)\n",
       "        {\n",
       "          batchsize : LongStorage - size: 2\n",
       "          size : LongStorage - size: 1\n",
       "          output : DoubleTensor - size: 100x256\n",
       "          gradInput : DoubleTensor - size: 100x64x2x2\n",
       "          nelement : 256\n",
       "          _gradOutput : DoubleTensor - empty\n",
       "          _input : DoubleTensor - empty\n",
       "        }\n",
       "      8 : \n",
       "        nn.Linear(256 -> 200)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 200\n",
       "          weight : DoubleTensor - size: 200x256\n",
       "          bias : DoubleTensor - size: 200\n",
       "          gradInput : DoubleTensor - size: 100x256\n",
       "          output : DoubleTensor - size: 100x200\n",
       "          gradWeight : DoubleTensor - size: 200x256\n",
       "          addBuffer : DoubleTensor - size: 100\n",
       "        }\n",
       "      9 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - size: 100x200\n",
       "          gradInput : DoubleTensor - size: 100x200\n",
       "        }\n",
       "      10 : \n",
       "        nn.Linear(200 -> 10)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 10\n",
       "          weight : DoubleTensor - size: 10x200\n",
       "          bias : DoubleTensor - size: 10\n",
       "          gradInput : DoubleTensor - size: 100x200\n",
       "          output : DoubleTensor - size: 100x10\n",
       "          gradWeight : DoubleTensor - size: 10x200\n",
       "          addBuffer : DoubleTensor - size: 100\n",
       "        }\n",
       "      11 : \n",
       "        nn.LogSoftMax\n",
       "        {\n",
       "          gradInput : DoubleTensor - size: 100x10\n",
       "          output : DoubleTensor - size: 100x10\n",
       "        }\n",
       "    }\n",
       "  output : DoubleTensor - size: 100x10\n",
       "}\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- make a data batch\n",
    "batchSize = 256\n",
    "local inputs = torch.Tensor(batchSize,1,32,32)\n",
    "local targets = torch.Tensor(batchSize)\n",
    "local k = 1\n",
    "for i = 1,batchSize do\n",
    "     -- load new sample\n",
    "     local sample = testData[i]\n",
    "     local input = sample[1]:clone()\n",
    "     local _,target = sample[2]:clone():max(1)\n",
    "     target = target:squeeze()\n",
    "     inputs[k] = input\n",
    "     targets[k] = target\n",
    "     k = k + 1\n",
    "end\n",
    "x = inputs:clone()\n",
    "y = targets:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 256\n",
       "   1\n",
       "  32\n",
       "  32\n",
       "[torch.LongStorage of size 4]\n",
       "\n",
       " 256\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x:size())\n",
    "print(y:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function hessianPowerMethod(inputs,targets,param,gradParam, delta, filepath, modelpath) \n",
    "    local maxIter = 20\n",
    "    local criterion = nn.ClassNLLCriterion()\n",
    "    local model_a = nn.Sequential()                                                                                                                                                \n",
    "    model_a:add(dofile(filepath .. modelpath))\n",
    "    model_a:add(nn.LogSoftMax())\n",
    "    local model_b = nn.Sequential()\n",
    "    model_b:add(dofile(filepath .. modelpath))\n",
    "    model_b:add(nn.LogSoftMax())\n",
    "    local d = torch.randn(param:size()) --need to check\n",
    "    print(d:size())\n",
    "    \n",
    "    local d_old = d*10; \n",
    "    local param_new_a,gradParam_eps_a = model_a:getParameters() --I need to do this\n",
    "    local param_new_b,gradParam_eps_b = model_b:getParameters() --I need to do this\n",
    "    -- in order to reflect loading a new parameter set\n",
    "    local numIters = 0\n",
    "    while torch.norm(d - d_old) > delta and numIters < maxIter do\n",
    "        numIters = numIters+1\n",
    "        epsilon = 2*torch.sqrt(10e-7)*(1 + torch.norm(param))/torch.norm(d)\n",
    "\n",
    "        print(numIters) --comment this out\n",
    "        param_new_a:copy(param + d * epsilon)\n",
    "        param_new_b:copy(param - d * epsilon)\n",
    "\n",
    "        --reset gradients\n",
    "        gradParam_eps_a:zero()\n",
    "        gradParam_eps_b:zero()\n",
    "        \n",
    "\n",
    "\n",
    "        --feedforward and backpropagation\n",
    "        local outputs = model_a:forward(inputs)\n",
    "        --local outputs_b = model_b:forward(inputs)\n",
    "        local f = criterion:forward(outputs, targets)\n",
    "        local df_do = criterion:backward(outputs, targets)\n",
    "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
    "        \n",
    "        local outputs = model_b:forward(inputs)\n",
    "        --local outputs_b = model_b:forward(inputs)\n",
    "        local f = criterion:forward(outputs, targets)\n",
    "        local df_do = criterion:backward(outputs, targets)\n",
    "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
    "\n",
    "        Hd = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
    "        norm_Hd = torch.norm(Hd)\n",
    "        -- normalize the resultant vector to a unit vector\n",
    "        -- for the next iteration\n",
    "        d_old = d\n",
    "        d = Hd / norm_Hd\n",
    "        print(torch.norm(d-d_old))\n",
    "    end\n",
    "    \n",
    "    lambda = torch.dot(d, Hd)\n",
    "    converged = true\n",
    "    if numIters == maxIters\n",
    "        then converged = false\n",
    "    end\n",
    "    return d , Hd, lambda, iConverged\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 105506\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "1\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "325.66338359894\t\n",
       "2\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0282461634857\t\n",
       "3\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.21452748456694\t\n",
       "4\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.075246076967043\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.026656046466931\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- usage example\n",
    "local param, gradParam = model1:getParameters()\n",
    "filepath = \"\"; modelpath = \"\"; delta = 5e-2\n",
    "v, Hv, m, converged = hessianPowerMethod(x,y,param,gradParam, delta, filepath, modelpath) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.265722508612\t\n",
       "true\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (m)\n",
    "print (converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function negativePowerMethod(inputs,targets,param,gradParam, delta, filepath, mEigVal, modelpath) \n",
    "    local maxIter = 20    \n",
    "    local criterion = nn.ClassNLLCriterion()\n",
    "    local model_a = model1:clone()\n",
    "    local model_b = model1:clone()\n",
    "    local d = torch.randn(param:size()) --need to check\n",
    "    print(d:size())\n",
    "    \n",
    "    local d_old = d*10; \n",
    "    local param_new_a,gradParam_eps_a = model_a:getParameters() --I need to do this\n",
    "    local param_new_b,gradParam_eps_b = model_b:getParameters() --I need to do this\n",
    "    -- in order to reflect loading a new parameter set\n",
    "    local numIters = 0\n",
    "    while torch.norm(d - d_old) > delta and numIters < maxIter do\n",
    "        numIters = numIters+1\n",
    "        epsilon = 2*torch.sqrt(10e-7)*(1 + torch.norm(param))/torch.norm(d)\n",
    "        print(numIters)\n",
    "        param_new_a:copy(param + d * epsilon)\n",
    "        param_new_b:copy(param - d * epsilon)\n",
    "\n",
    "        --reset gradients\n",
    "        gradParam_eps_a:zero()\n",
    "        gradParam_eps_b:zero()\n",
    "        \n",
    "\n",
    "        --feedforward and backpropagation\n",
    "        local outputs = model_a:forward(inputs)\n",
    "        --local outputs_b = model_b:forward(inputs)\n",
    "        local f = criterion:forward(outputs, targets)\n",
    "        local df_do = criterion:backward(outputs, targets)\n",
    "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
    "        \n",
    "        local outputs = model_b:forward(inputs)\n",
    "        --local outputs_b = model_b:forward(inputs)\n",
    "        local f = criterion:forward(outputs, targets)\n",
    "        local df_do = criterion:backward(outputs, targets)\n",
    "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
    "\n",
    "        Hd = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
    "        norm_Hd = torch.norm(Hd)\n",
    "        -- normalize the resultant vector to a unit vector\n",
    "        -- for the next iteration\n",
    "        d_old = d\n",
    "        Md = d*mEigVal - Hd\n",
    "        d = Md / torch.norm(Md)\n",
    "        print(torch.norm(d-d_old))\n",
    "    end\n",
    "    lambda = torch.dot(d, Md)\n",
    "    if numIters == maxIters\n",
    "        then converged = false\n",
    "    end\n",
    "    return d , Md, Hd, lambda, converged\n",
    "    --]]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 105506\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "323.75960107323\t\n",
       "2\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010916018972914\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010792803781953\t\n",
       "4\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010744250550398\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010702475106055\t\n",
       "6\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010688532388855\t\n",
       "7\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010660427763633\t\n",
       "8\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010660586873915\t\n",
       "9\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010619973046994\t\n",
       "10\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.01062737269947\t\n",
       "11\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010606507415119\t\n",
       "12\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010738838754573\t\n",
       "13\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010710329951754\t\n",
       "14\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.012455565512877\t\n",
       "15\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010695859930691\t\n",
       "16\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010718312556689\t\n",
       "17\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010689271569655\t\n",
       "18\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010715643798239\t\n",
       "19\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010685813466764\t\n",
       "20\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.01071355859302\t\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- usage example\n",
    "local param, gradParam = model1:getParameters()\n",
    "filepath = \"\"; modelpath = \"\"; delta = 1e-2\n",
    "v, Mv, Hv, lambda, converged = negativePowerMethod(x,y,param,gradParam, delta, filepath, m, modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.28782161262\t\n",
       "45.265722508612\t\n",
       "-0.022099104007943\t\n",
       "-0.024696911466884\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (lambda) -- largest eigenvalue of mI-H\n",
    "print (m) \n",
    "-- sanity checks\n",
    "print(m-lambda) -- smallest eigvalue of H, should be of less magitude than m\n",
    "print(torch.dot(v,Hv)) --should  equal m-lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
