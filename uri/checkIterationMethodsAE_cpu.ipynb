{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:c4db2055ad255533505115fd02f9b781538f0c885d11cdd36d9413bfe581a669"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'nn';"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- load data\n",
      "dofile 'dataset-mnist.lua'\n",
      "\n",
      "geometry = {28,28}\n",
      "nbTestingPatches = 10000\n",
      "testData = mnist.loadTrainSet(nbTestingPatches, geometry)\n",
      "\n",
      "print(testData.data[2]:size())\n",
      "print(testData.data[2]:max())\n",
      "print(testData.data[2]:min())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<mnist> loading only 10000 examples\t\n",
        "<mnist> done\t\n",
        "  1\n",
        " 28\n",
        " 28\n",
        "[torch.LongStorage of size 3]\n",
        "\n",
        "1\t\n",
        "0\t\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "--create minibatch\n",
      "batchSize = 1000\n",
      "inputs = torch.Tensor(batchSize,1,geometry[1],geometry[2])\n",
      "targets = torch.Tensor(batchSize)\n",
      "for i = 1,batchSize do\n",
      "     -- load new sample\n",
      "     local sample = testData[i]\n",
      "     local input = sample[1]:clone()\n",
      "     local _,target = sample[2]:clone():max(1)\n",
      "     target = target:squeeze()\n",
      "     inputs[i] = input\n",
      "     targets[i] = target\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- load model\n",
      "local modelPath = '/home/uri/Desktop/HFSF/results/2016-04-05/trainedModels'\n",
      "--modelFile = modelPath.. '/mnist_big_AE_model.lua'\n",
      "--paramFile = modelPath.. '/cpu/mnist_big_AE_sgd3000.net'\n",
      "modelFile = modelPath.. '/mnist_small_AE_model.lua'\n",
      "paramFile = modelPath.. '/cpu/mnist_small_AE_sgd3000.net'\n",
      "model = nn.Sequential()\n",
      "model:add(dofile(modelFile))\n",
      "--print(model)\n",
      "params = torch.load(paramFile)\n",
      "--print(params:size())\n",
      "modelParams,_ = model:getParameters()\n",
      "modelParams:copy(params)\n",
      "\n",
      "for i = 1,10 do\n",
      "    output = model:forward(inputs[i])\n",
      "    itorch.image(inputs[i])\n",
      "    itorch.image(output)\n",
      "end    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABL0lEQVQokb1RPS8EURQ97868N4TGUtpS4w9IVFtLNJL9B2qJZNuVrbRqtUZDthHR+ChEQhRCR8OKQoisjJ2dr3cUsmtmjEbhdPedc+49OQ/4f6jsIMOJ9ndV8U05OmjXugJapJWzBR1nNIvsxZZfSLkHPXQqTnciAyJ28HBv9OOS2Ixx/Ih+Sr7tsAkDJfnTkweMyfrUZg2jRueDOZipH5NrpakhY9giO3BKaRnBOf27sAFdwkJwQRtyBU5pIXJJ2+f8gM2JjNpmdxadEw5WfQf2Irt69YyPVrUYSrkazd2EDNkqMAoay9evDPoB14tfJJjzXxj2GXIDXpZTmKi+R4wDm3bb8CTnMzhlQlreHLq5lS4Ai/2nniCpNG61WJb1A0CbYisAoAUAVGR/6P+ITzjdg5JkisAdAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABlUlEQVQokbWSz0sbURDHv/P2mWwSBBNMCgYRxQgSFINF+i94KXgSROixPfRsj/0nevWqh56VQnuqgmKE0n9ALbFB1h+razZuNs+ZHnaTNUgvhc7lPd5nZt53vgzw34PiU/2VACDSA28k0Z1I25l02CGX+5AEpPMzLydUqfIix9ffd46bDEQNFKv8yvp8TrHhIYVM7eBRhzG0RBXevS1qgFtXJsfO56/XXcRQQKW5FBt0Lr/t/m57gd9hALAAEAGkRoZ8v7G3fdxwvLYRUAwBSNi40jrF7o/zqCiBJODA6dYmR233l8/9ga1eFof3C7NaJmeDi3CwEgC49TO4KU1Xl8uHD4OORdPaU7ttY9yNdAzVEw8lvPWEKLc6rp5DqKywAPmyRYSeCSBSlog1urakRTpnTpysI5YqVrK69nrKlrB19PHUQPpK0vbY+7rjPRg2d/tv8taA2Eyhuuk9Mgv7n8Y1oadFA0Awok4uU5rY+7DVFgBEnAil4bHFV4Xml3qLk8VI1oSgtekKnrLkYwWJJVKi9J/jDxrrnnYhj5hiAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABO0lEQVQokbWSvUpDQRCFz+7dm028EsRItEmhYGOd1sJK30A7K8HGSrD1IXyAgCl9AIkIovjXWKVUQSJYWuXH3N27x+Ki3N2kzTTLMPPtnDkMMJMQQRoDIuX03sjLVBETrtbpZ/XdrnRTwNInOeZm8AEAYLnWo7HWZiMVluZwztSR9oemEsxUw8YGZArGGjChzNUXWtLy7vCLx96KEo0uR268v3fQxCM/ipIEau9MSaOACh74mhfln5y1fnyUrIs4FgDi4kSBJnmKEgBZwT3fcjJXS/VkFSAEo2ylqn0SasTvHShEcuGShmf/4/It2Ua1pLF4RbZOAv+HbEMLzN9mbGlo36EI2zdl58rNQXI9TgY+aVxGkikv9FLoetQjScdnT2juoWC905eQZiuDmDySyHs8Mr8sAOkENYP4BWA4fq3ogqmOAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABr0lEQVQokbWSz0tUURTHv+feO8/BURs1UpQG0UhQlzag1CIwxK2u3ERCEESr/oU2LSICCdy4dC06RC0EQYqBCaIMyvyxGVEX6jzGyZn3nu+d0+JNzptxGR24l8v93s85F75f4L8UXb0gYgnPuv4VaRMjgearJJmeB+P0c23LgUhjc92f+e15xXe3NUg1jFOpNY+FufjMAhTCVQX1wEIazBB9J6FIoh+CGXkz1hRUKn5QvsjaAglFAgA9+Dodl7PN3K+y0OluAK6R1PvibrOcZOYz2VIq6X099wQwAEAC6+H95mBn/sOxb6yJ/oH2A0FVBOHmo2vBzpMfFYZfJCsuAWpibK5bDp9/YQHQ3kEHZxwRk/fgLOcYBLROdlW2C0yXM1Wq08uvuCBjdc7NtOY/nddIRW3a3dsX6BtTs0Om8PG7K/RXZFImluix0ft4+roubSweB3JJipR0y+jLz8mhWwm2l17ZHLVK9216/oXjuM7p+mRTvR1Gtb0tMzP7R087VKPPyhp9bztOYXU4VpeLcFema7jv5FveDQNAEsUJZLTvV7NBEuUBKAgAiUj/Un8Akqaqllt5eGYAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABE0lEQVQokb2QvUoDQRSFvzs/u50kYqXBwkLsBCGPIIK9nbVP4CMIeZB9APERLGzFJpWghTYSEEmRhP2Za7GZ3ahLSOWp5p5zz8w5A/8P6eCMUG26b1179twuHjAABki4L0zjq9hPB7XdAIpvjUnITnhEoyiEVlSExUXNGLD52VGbQlBWbkrJdOaa4fxT58vJAJSILL3KsF/ETbfcUMSi1d7TtB/8sJQmEJZ84K6KSa7vOwc9M3trnYExWy+C9sZfbr57yOmHraJYuJE/nhqptq+fk/wyw9Qt6zdLd1MX9YnLHYRYzAGU3gNIHpRy5cvr1AWdMN10p6gE0BjolygYkB+BWgRe76pJdK6F/UOkVjcxrsc3LqxSzpfRFMUAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABtElEQVQoka2Sv24TQRCHv9m99Z0vIXGIDEEEbDqKSLhGCCoK0tEiJCTegIqOglfgRSJeggLEvwAFCIECggjxJ7ZzF9u7t0PhMzGIgoKpdvRJOzM/ffC/Sv7eCAYUUFH9HYpJYowoiAhUACQ1SyVGRQHUJFFVAQuAydeMV0EASVpdW0aZQVnoun5QjKCYk9c2/ZuA1N+m3c67UEWMC17tlVvJ8D4oGECWz7WdqCKpRRavH18q/XQaII1TedOoxjjxSG/D+q0KqbfVI5k2qJTKK/nNPD5+AaI1PMjSlgLijD1/0QzuTqZxJAAfzerqwkjdmUs/2jdO8P55nVACEG261huuX73s9srTrtofMwe1WYw73QsbuT/oRyWTeejCh+1vzwaN1qN7/TubtkgARKdw6dOTpwN9tdV8PeT2ytkvAlBvy7G3L/eChhIf+fpgZd+JInVCTHaGQYneR3BVwaLhV0IUu2OAGMGudzLbbsjhnX0J9WXkvezzTnBeqxks05kXtjV8ONot0vHkUBOTBFVA7PLR3Bdl/K5zDhkUBbGZIxgGOu9QFKOASMCGEX/YN3urKP9WPwE1e7wCrdCDhwAAAABJRU5ErkJggg==",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVQokb2QPU5CQRSFv5n3GAKxM7GT2obC2JuwDOMydAfGBVjbQWVnLEhYgI1bsNDEThobdeYhc2zg8ePFEAtPeU7Ol3sP/L/cD8c7mP6BFDhPz0+lmTU4UdRkFvrVCyZ0+dpEbV4qaXRtYR37etdw1/gB4EZRp+wYScGtKvWDnxeXDxJHZB6rUtYbD6p0RdM6lIGi7gkLq8b61DmgkYbmroELRb1QYDQdkYIzs1jQ+1A96qo8h5rm/Nlac2fQNm/uuJWsEEQgr41azqPx3eveGGObTao5PshVefvi7/oGW0RKkIAp90MAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABc0lEQVQokbWRMWtUURCFvzP3um/35UEIIWEL0UYsgqksLCxCGpEQ/APif7C2tNE/YGmjIAg2doKFhY1WgpWVWIisWQmGxAXfvnvHYvfl7Uo6cZp74ePMzDkD/72k5Rex8PGWKQEQOh1yIKxvX4kT8lJLOxcDoM1Hn7882SoLAXGGXMFyAnTjdpW2S8+hAZszyR1g9U5pfB01KbdKF0Lmmd7+ltL3x+Om2xQpxF6/F4urb3/VP+5WaucBkmSxXCkvvjie/nywsugVCRSKwcb9o6Z+ufZXNAAK/d1RyuNrOgNiq6+mPn1anREdinuHOY92omZjlmDYfP471w8rMwuSrIUB0ODmpyZ9HJqsVwSTnYYAhOH+ejq5d5Cl4HKczqsGuzuD+vWbjPu07WjzEOKFW0M7eTYBPHumUypQXb9U5IMPs3M7rlPYFL218viofjeRgyOUO6/qlxuXz4/ff2vmG/hiEIrEkOq0xLogzNxn927Rv9QfddR5mXX0+EgAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABFElEQVQokc1RO05DMRAcO+/FhAIkBBUkF+AGHICGhgIhISJK+tyAKlWk1HSROEJqKJAQDQ0VQqJAIKioII9gP78dCkISGx+Abdb7md2ZNfDPTKUCJhq1ihKzWOd2rSEAoF6rPzis3rEi6bkRboPC5t4lPyjeO65HxToOObJyMmD1xWZY1GjdlgU72GLBbjx05YGWx7i6F3Yjgag9evaX1Q3F8gB5SDVzrhy9jVladlCP5V5TSIrjGcwM8lPjzumnVuXuEnSsH0AOoIZnBsjfRm+MyfWRC5lMPC2gpR1ymV+hsB0m5t/ECyBJSgCQvfOigfhbJ2ZcwWFaDoAex2xPzxeNWNy3C+dPWpLI8OQRUmVQfor7Bu7ibZGejwMUAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABdUlEQVQokbWRvUoDQRSFz52ZzY+bxZ9oIBb+FGon+gABbcQHEPQZUucBfIhU9hYWdoKdnY1dsBPFgKholkjMupvdycxY7GY3oGIh3mbuzDcc7j0H+PciSs6v5MfLNyq/UpF0BiBWsC0Uy+r+TQNkkl+MAPByo+31Xrt996TCiNi4BM02P7Ty+5GSt2sMxAEwADAA8vsHufDxrCUB792MTUQAbbY893h14ehj2D+0Kd0ZIMA57fmX68XawzA4XxaUMRDEznMUXu3VO0q1azkuLJ5Bmm72ZfTSDrQJG0Vi9lwh3dOI+aqEDB0O9Xw6MMQEyCSQWP7aDq4fN7YXcdM1MNIfjjwAE0u1rZWZUqXeDS6mADDOMlnt9qJIQT4xXrYA6HjYGCLwjQFkN8eckmtiWxKHYJQ2ALQHWE7qagzTjf1AeVMWjZ5SbwGAz/vSzAoiigPLNABR3UU0KIk0TDGWPZ+IOsFdewDSWZSjhhemJ0PX0wp/rk+4R44W/K/WSQAAAABJRU5ErkJggg==",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABK0lEQVQokb2SPy9DURjGn3PPvVejGyZpFyIx2Ng6kJhMUqmNRSwktn4OH8EiMRgtUrFa8A2kQttJUiLB1fOeex5Lb/Wesvbdzvmd53n/nBcYfyjvrAE4/vVQeYLgF4Ugyq/Pj8ny0O0gwcx0i46GVT+ZwuzSJa3r0QlLHo2wwy+bsH1NM4BhHxIWRhfcfnFdIr8ghRBxXN9uTA1ZZkqLq7UkukvxjdEuVQAEuH976jJlOV+Q0sXJY344koY1xLHOFXtIETYMrThuerZHNMKzDaHYJJHdvQoyrUKdIjypvpM3F7SfhqeY6EONNp3l+QPZmV882OoyB5tMnaOwO4cIWKmsLgwmoNGmI3vSKyEM4ijXSIDbl1bT1FBQAQBorUc+Df5iqMwY/6zHuOMH0N+MOrMXAkcAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABuElEQVQokbVSPYsTURQ9931MktEsZvFjUVEMiOwKwqJsIxYLIrJgY6FNfoK1P8DK0lJEe2tBcBUrK6td0rgIWuiuQkz2K5nNm3nz7rWYmSS9eKvLPfccDvce4L8UzbQkBNKK1JEUE11BCiIASGmlrMpnQVJcrChjiAObYrNUZADQxy9fvzI//Ph54FFMAEArgOzVt4nPMp9+u9coOAYAFAlRY+3ZghJhUtYHTEASFqiFtRZJ2q/H/H0rl9IkABERjL7uDbsPH7zpH24MpDBjAAgECPvvdfq6d+Zs07sgU1kAgIRfH9zesaerJjunaQYkASi6tLLb7NyPYJdOpoGnTALVbj5us7tgAJy+s95zkPJCRHbu9pNrJ+KIAM7GhndH4ErWLN7ttA0754ceHC6uHvWT6ra1+FHnvBWX1ON8a2MnxE3fTULJ1K0bpyyYWjVKN9fD8q25huWJIVvXgOhI+U8vftPOn6WfozAB0x/tWBJnDl49HwttJ18OhlKB+ejlYJE233V7HoD4fZf6SUwojpqN8WFS3dvU0myaIaoHMHOVJYNsNiZBC6rXk0JedtWEioABRGXzL/UXvV+8MlOZROUAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzUlEQVQokbWQPQrCQBCF32SzCR5BxAuIlY21nsEzeCXT6zkEC7GS4BVs0wiBkHVNxso4u25AEF83883PmwH+IpKBJrDtKYyoBwDQyPI8gw6xBBs2fEQiRglcgsHgoDXSF3Y730qx45qvU6gAVFgWbHiLNLCzifarMoG8Uxhq08MNziXSrXUiDxIYUOIWrxZoxLs/4GRsojC0MLM14jDUINT+rJehectcLbofyU7G+c7VYNQl3bFKkfxs7MDHSZthgTa81jfhKAHIftX4g55l8DoUUcVlUgAAAABJRU5ErkJggg==",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABY0lEQVQokbVSu0oEQRCs7pnzHiyCh2CiciKKIIJ/YOpf+B/+j4mBPyBibGAihp4onPg4FJF7eLuzXQY7u3vGYifTTFPV1dUN/EvIfCrqmBuF8ceVJQXEt9oMVkPKRyB+7ejg++RsRACo0ICo8+2N46csvdnWGuVjRkCWE0d8sGb0AKAGSBgNxm17ltiGhQ6AAJhP+4PxrLWqAHTBR5FRFPOvl6C9g0RF1KuWyCI4fDC3uL+kAEJmsRhVp48Xn9RGZqQFwy8k8/HVvfLlywBjrTbOYtMVb5LVjeKcnmaQ9Z7HTuTSvKT1jZYT8XuOst6td6EAoAtJx4u4yTBY97CjArLaijQTmQVgnOy0Gt3rd4vOF7Q2mea08HweXHNrt3KtEJQGBoLZm1c2Ib+MRyiM4AjMX+8CIFI6BEaTZHL5/nR6Gwixam+FBwC0u5n2R1bewdyBFUO5NFQXVhWFAEQFJjn+HD/2n5Z6P/RmzAAAAABJRU5ErkJggg==",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABJklEQVQokb1QrU7EQBic3W7Tu17gFc5C0CDO8QAoHEFhMARDMDwBgpAQDAbMaQi8AB5FciEBQwgUBeHElUB/bncQ7d62VwWCUd/O7Mz3A/w/RKWWk4f+lbOVHG+8KQCQ2Vxa+6Swxm8WMHyCV5AOOQIBEBQTh42X8FsXn3phyQjLWlFjcDjs7I+w3s8DHME0xwvRfaBmopoSoK7vaMi8PUVjNXuMIpqcMRdrt4GHHlOSSZZxp9jDQWL+g5okmbJn1bK1Ce9X9t6VyLvLBgRrTt+lx84pS+fZ1RZmO3rmAGrKKXFJ9tHG+YC60rNMi5iPnl9fxkwzbts4J6ZjkmT8tWsHqMaShje3J1DuAGXlnSrChJtD4en6Hm4VP6hF2owAAJA1XH/EDw+vjgbB4ciDAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABoElEQVQokbWSPUtcURCG3znn7F53WZJ1FQuNkQRCUmypFmIjaKxNJGBhYf5AykDqgH/BMl2qfEJSKUgiKoKlghgEcVUULda47nrvmZkU99796EIg0xw4z5n3zMw7wP8O+ktEnQcJiJwlFWEFSLUJiUBu8MWzgS5frZ6ufD2OFJLKGGNzo6s3LMKeOdyZyBkLwCaJtjg/XTDghrfGFAurdVXAAQAUai7PAt1/92tqoUS2J9Z0AEgBvvrhsbHXcJhXitar0lG9K94rBcaWlq58tPfQECGVBSCe80Hm8cJkVq7fHkmrbwJgH7xeuwwbN2F4/bHYPhQCkHt1xqLio8bJrE3uUlly/VlAbtmgXtG0jjiTDL4EI9Hy+dOxu0hZDDOSDdzum1A0/2jS0h0jcX8xzJTLlc3fDOp7nlfpdKh39NPpweJQV2ZoO/L17/ctQM0H/XMVz+Hx528XnsOtsuuwt2fmhEVERLj2YdACINMyfvh9nUXY17bnCgQApm0T6MnL8e7bw58r+zVBYkXbmhibRRQl7ies9bGBJt1Tcwj/Hn8AERepchvY+F4AAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoUlEQVQokb2SMQ7CMBAE1zZOXpCSH/Am/sCbKCjhDUiR8gkqSnqEYvCmQ7dWHEUUXGeN7m731sD/y9mHd/j8MiTi/Brg52GDnryiMWssJhBEQ1VdCdMSjHWYsH+AFchwe9bHEg7e9lroQGQrWQ+SsN2NYvVbAXfyiHa2M+PwFq8q6JLEq+6MesBC0ChpF/FFiWUjjKeuX/tTCsdtRF7XuFwTSc0msuBpS58AAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQ0lEQVQokbWSPU4DQQyFn+0NbKJEiSiIEA1FRMEBOAJcgbtwHI5BjZAoKGhpQfxJECJI0GbGj2Ims4EW4WrGn/2s8RvgX0J+HEVAUpgz9quKXLtkKELABjv9ZVirtaKo1j88PX69D7kaQFXqxEYnR9pcLlrZCgCUoAh6k1r3NnOfryAJ0B0ebCEA1KpIAlpE6PEthEYFIhu1tTNTzO+CsBIhlMGROplbpzfzYAqCoYnIEGkj/nX9rBoIMLoUmF6F+LDoDIUAHGsQqgKgu1VvjwAw0wTNOiaQLjjYV0BIFiiJafO01INaAI9kK+sE6C/n07A7VCHd25lx2UTCPy7mNh4kO1nW58lGf2c17mZjy0zP3ndro0rxM3UmJelNZvo4iwBSwtoliFqYXZ3dhhVb/2CA1iObfcbywwoUAqpGd4n4c3wD5OONjOu04TMAAAAASUVORK5CYII=",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABIElEQVQokbWRP0sDURDEf+/+kgQbC0HQQrBNYySiFpba2hvQTi38MFqJXfwUVoKggmAbwUbOBNKEWBjjmbvc2OQwuSSFoFM9dnZ2dvbBv8CeWPWs5JeKAczjOS7gDBctQx+c+H4lxGTJBMDr3azRRJlhFLdKGGuupmDM1uVOATNUlZxhMmSOa9Vg9VnvTobCY/9TDcqBFOXHhlYS9TeoSIfFjKPPrrrapKyO1kfXMSwoikN14ijRDn6aGwBRQrZPwZY5bc1/je7qhHq5qLbUDz+SxvJAksLW2zbcKlaoPdxUMjjcQfOKoxLtYz//QJyNaRW4lOoTv8vNcaJeuGi53o9heqjIMIu7VDfR8JrpQ7w+dboTZk7DUFzbUaTpnX+Hb0fKazXVi4brAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      },
      {
       "metadata": {
        "png": {
         "height": 28,
         "width": 28
        }
       },
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABrUlEQVQokbVSv2sUQRT+3psZd/cSFr2IdxJIk0pUImlMCCgKIpguqfwP0ulfEbCySJlCbAIpAhamiQRBG9MFhYAkiinEJOTO3Hne5m535lnM7d2epeCrZvge730/HvBfigpPAokIiET+ApmdAAIASqELAFC9Hm0gYP/RlWrWlT5IpqwyASsRwEwtP752fCyA9jOjJLECMQTQlZVbqYx/bsFPYmq3UicIpycY9GAqCFuHrs+TCQAuLH19EVH8wbqz+cgMC1IPa+lOrGd/2s5yQEFBIcATu1m2OhI/+/V7o1TQqAhkqs8baf3OxZm339cuDxvApRsrR+fJp/mF9f3tSSqCxNHdN2fdtHty0DxvrI7mNHo6y49uRgQpXVJEPV9yE5gCewqgE0eQ5FCReI4etLVXX8Iwvj1Hrv56S9ghDwZgcBiXr957l3Q+LlZGA6MoD8EvZzP29Efy7bom0mGoBmMBwKnq/bD9ZE9ACOCcDHYCpCfLzbVNAYS1CNscdCxg03xff5kBgFgrdnAmxNAjY+qo6bxhlBbPBARKG20fonCGIRCELHPihfWD/uf6Axmsmtsx59aBAAAAAElFTkSuQmCC",
       "text": [
        "Console does not support images"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local criterion = nn.MSECriterion()\n",
      "--criterion.sizeAverage = false\n",
      "local outputs = model:forward(inputs)\n",
      "local f = criterion:forward(outputs, inputs)\n",
      "--f = f/inputs:size(1)\n",
      "print(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.0094010300606736\t\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function hessianPowermethodAE(inputs, param, delta, filepath, modelpath) \n",
      "    local maxIter = 50\n",
      "    local acc_threshold = .2\n",
      "    local criterion = nn.MSECriterion()\n",
      "    --criterion.sizeAverage = false\n",
      "    local model_a  = nn.Sequential ()                                                                                                                                            \n",
      "    model_a:add(dofile(modelFile))\n",
      "    --model_a:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local model_b = nn.Sequential()\n",
      "    model_b:add(dofile(modelFile))\n",
      "    -- model_b:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local d = torch.randn(param:size()) --need to check\n",
      "    d = d / torch.norm(d)\n",
      "    \n",
      "    local diff = 10\n",
      "    local param_new_a, gradParam_eps_a = model_a:getParameters() \n",
      "    local param_new_b, gradParam_eps_b = model_b:getParameters() \n",
      "    -- in order to reflect loading a new parameter set\n",
      "    local numIters = 0\n",
      "    while diff > delta and numIters < maxIter do\n",
      "        numIters = numIters+1\n",
      "        epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(d)\n",
      "        --print(numIters) --TODO: comment this out\n",
      "        param_new_a:copy(param + d * epsilon)\n",
      "        param_new_b:copy(param - d * epsilon)\n",
      "\n",
      "        --reset gradients\n",
      "        gradParam_eps_a:zero()\n",
      "        gradParam_eps_b:zero()\n",
      "\n",
      "        --feedforward and backpropagation\n",
      "        local outputs = model_a:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "             \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_a:div(inputs:size(1))\n",
      "\n",
      "        local outputs = model_b:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "        \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_b:div(inputs:size(1))\n",
      "  \n",
      "\n",
      "        local Hd = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "        local norm_Hd = torch.norm(Hd)\n",
      "        lambda = torch.dot(d, Hd)\n",
      "        diff = torch.norm(d*lambda - Hd) --TODO: comment this out\n",
      "        print('|Hv-lambda v|: '..diff) --TODO: comment this out\n",
      "        print('lambda: '..lambda)\n",
      "        d = Hd / norm_Hd\n",
      "    end\n",
      "    converged = false\n",
      "    if torch.abs(lambda) > diff and diff < acc_threshold\n",
      "        then converged = true\n",
      "    end\n",
      "    return lambda, d, converged\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maxEigValH, v, converged = hessianPowermethodAE(inputs,params, 1e-7, _, _) \n",
      "print('max eigenvalue of hessian: '..maxEigValH)\n",
      "print('did converge: ')\n",
      "print(converged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0049169403623227\t\n",
        "lambda: 0.00017474938751053\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.076144558480932\t\n",
        "lambda: 0.26595172495303\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.060864618648121\t\n",
        "lambda: 0.30160077914532\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.059535379995958\t\n",
        "lambda: 0.32532802363994\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.058955285686656\t\n",
        "lambda: 0.34669296870202\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.056505897586756\t\n",
        "lambda: 0.3661753562902\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.051146439085361\t\n",
        "lambda: 0.38272216779712\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.043721195780275\t\n",
        "lambda: 0.3953728129881\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.035745349212627\t\n",
        "lambda: 0.40414881779479\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.028368335035324\t\n",
        "lambda: 0.40981429444924\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.022119361623888\t\n",
        "lambda: 0.41330677191893\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.017086914697551\t\n",
        "lambda: 0.41540381244739\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.013147032434598\t\n",
        "lambda: 0.41664679304722\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.010108931169567\t\n",
        "lambda: 0.41738025929058\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0077839432783706\t\n",
        "lambda: 0.41781340963259\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0060104673397447\t\n",
        "lambda: 0.41807026975856\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00465868965407\t\n",
        "lambda: 0.41822357250497\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0036275745446596\t\n",
        "lambda: 0.41831581997517\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0028397234566196\t\n",
        "lambda: 0.41837186683174\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.002236301933157\t\n",
        "lambda: 0.4184062960971\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0017727396727294\t\n",
        "lambda: 0.4184277071284\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0014153125063205\t\n",
        "lambda: 0.41844120272217\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0011385074511251\t\n",
        "lambda: 0.418449833163\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.0009230210908041\t\n",
        "lambda: 0.41845543715063\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00075424822436452\t\n",
        "lambda: 0.4184591335621\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00062114172808669\t\n",
        "lambda: 0.41846161048114\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00051535058519592\t\n",
        "lambda: 0.41846329604445\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00043056592400841\t\n",
        "lambda: 0.41846446008472\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00036202323924987\t\n",
        "lambda: 0.41846527503341\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00030612288445287\t\n",
        "lambda: 0.41846585270928\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00026014098085973\t\n",
        "lambda: 0.41846626673281\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00022200994690754\t\n",
        "lambda: 0.41846656632769\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00019015278011323\t\n",
        "lambda: 0.41846678491058\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00016335871958364\t\n",
        "lambda: 0.41846694549589\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00014069055844275\t\n",
        "lambda: 0.41846706415767\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.000121415930189\t\n",
        "lambda: 0.41846715226112\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 0.00010495656781403\t\n",
        "lambda: 0.41846721792946\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 9.0850917206792e-05\t\n",
        "lambda: 0.41846726703428\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 7.8726573549839e-05\t\n",
        "lambda: 0.41846730384645\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 6.8279916780008e-05\t\n",
        "lambda: 0.41846733150018\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 5.9260988352656e-05\t\n",
        "lambda: 0.41846735230798\t"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 5.1462183438594e-05\t\n",
        "lambda: 0.41846736798768\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 4.4709720659767e-05\t\n",
        "lambda: 0.41846737981407\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 3.8857141232235e-05\t\n",
        "lambda: 0.41846738874214\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 3.3780293984976e-05\t\n",
        "lambda: 0.41846739548608\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 2.937342370534e-05\t\n",
        "lambda: 0.41846740058485\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 2.5546077333122e-05\t\n",
        "lambda: 0.41846740443873\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 2.2220631541018e-05\t\n",
        "lambda: 0.41846740735507\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 1.933029053052e-05\t\n",
        "lambda: 0.4184674095614\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "|Hv-lambda v|: 1.6817443832054e-05\t\n",
        "lambda: 0.418467411232\t\n",
        "max eigenvalue of hessian: 0.418467411232\t\n",
        "did converge: \t\n",
        "true\t\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function negativePowermethodAE(inputs, param, delta, filepath, modelpath, maxEigValH) \n",
      "    local maxIter = 100\n",
      "    local acc_threshold = .2\n",
      "    local criterion = nn.MSECriterion()\n",
      "    --criterion.sizeAverage = false\n",
      "    local model_a  = nn.Sequential ()                                                                                                                                            \n",
      "    model_a:add(dofile(modelFile))\n",
      "    --model_a:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local model_b = nn.Sequential()\n",
      "    model_b:add(dofile(modelFile))\n",
      "    -- model_b:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local d = torch.randn(param:size()) --need to check\n",
      "    d = d / torch.norm(d)\n",
      "    \n",
      "    local diff = 10\n",
      "    local param_new_a, gradParam_eps_a = model_a:getParameters() \n",
      "    local param_new_b, gradParam_eps_b = model_b:getParameters() \n",
      "    -- in order to reflect loading a new parameter set\n",
      "    local numIters = 0\n",
      "    while diff > delta and numIters < maxIter do\n",
      "        numIters = numIters+1\n",
      "        epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(d)\n",
      "\n",
      "        param_new_a:copy(param + d * epsilon)\n",
      "        param_new_b:copy(param - d * epsilon)\n",
      "\n",
      "        --reset gradients\n",
      "        gradParam_eps_a:zero()\n",
      "        gradParam_eps_b:zero()\n",
      "\n",
      "        --feedforward and backpropagation\n",
      "        local outputs = model_a:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "             \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_a:div(inputs:size(1))\n",
      "\n",
      "        local outputs = model_b:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "        \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_b:div(inputs:size(1))\n",
      "  \n",
      "\n",
      "        local Hd = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "        local norm_Hd = torch.norm(Hd)\n",
      "\n",
      "        local Md = d*maxEigValH - Hd\n",
      "        local lambda = torch.dot(d, Md)\n",
      "        minEigValH = maxEigValH - lambda\n",
      "\n",
      "        local diff_M = torch.norm(d*lambda - Md)\n",
      "        diff_H = torch.norm(d*minEigValH - Hd)\n",
      "        print('|Hv-lambda v|: '..diff_H) --TODO: comment this out\n",
      "        print('lambda: '..lambda)\n",
      "        d = Md / torch.norm(Md)\n",
      "    end\n",
      "    converged = false\n",
      "    if torch.abs(minEigValH) > diff_H and diff_H < acc_threshold\n",
      "        then converged = true\n",
      "    end\n",
      "    return minEigValH, d, converged\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minEigValH, v, converged = negativePowermethodAE(inputs,params, 1e-7, _, _, maxEigValH) \n",
      "print('min eigenvalue of hessian: '..minEigValH)\n",
      "print('did converge: ')\n",
      "print(converged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0058107878394819\t\n",
        "lambda: 0.41825345474989\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00239028716867\t\n",
        "lambda: 0.41836330367099\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0013790524300759\t\n",
        "lambda: 0.41838434214439\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00099960502779295\t\n",
        "lambda: 0.41839202865013\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00083966931996656\t\n",
        "lambda: 0.41839637108073\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00075886290387221\t\n",
        "lambda: 0.41839956161193\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00070768900164344\t\n",
        "lambda: 0.41840221531511\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00066895632130094\t\n",
        "lambda: 0.41840454127123\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00063655201557592\t\n",
        "lambda: 0.41840662731662\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00060811685003974\t\n",
        "lambda: 0.41840852017238\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00058259634842338\t\n",
        "lambda: 0.41841025023164\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00055941974831802\t\n",
        "lambda: 0.4184118399714\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00053821739269768\t\n",
        "lambda: 0.41841330718931\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00051871822678634\t\n",
        "lambda: 0.41841466648157\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00050070901591699\t\n",
        "lambda: 0.41841593005636\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00048401563861823\t\n",
        "lambda: 0.41841710825578\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00046849290064343\t\n",
        "lambda: 0.41841820992525\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00045401806972254\t\n",
        "lambda: 0.41841924268986\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00044048632322255\t\n",
        "lambda: 0.41842021316766\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00042780734847349\t\n",
        "lambda: 0.41842112713736\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0004159027251731\t\n",
        "lambda: 0.41842198967208\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00040470387485763\t\n",
        "lambda: 0.4184228052472\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00039415043795917\t\n",
        "lambda: 0.41842357782811\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00038418897749945\t\n",
        "lambda: 0.41842431094243\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00037477193569423\t\n",
        "lambda: 0.41842500773971\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00036585678720642\t\n",
        "lambda: 0.41842567104135\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00035740534649462\t\n",
        "lambda: 0.41842630338261\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00034938319613959\t\n",
        "lambda: 0.41842690704805\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0003417592110661\t\n",
        "lambda: 0.41842748410191\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00033450515948495\t\n",
        "lambda: 0.41842803641389\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00032759536495221\t\n",
        "lambda: 0.41842856568152\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00032100641843693\t\n",
        "lambda: 0.41842907344947\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00031471693098346\t\n",
        "lambda: 0.41842956112618\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00030870731983503\t\n",
        "lambda: 0.41843002999854\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00030295962244804\t\n",
        "lambda: 0.41843048124458\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00029745733382521\t\n",
        "lambda: 0.41843091594472\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00029218526345367\t\n",
        "lambda: 0.41843133509152\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00028712940925276\t\n",
        "lambda: 0.41843173959848\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00028227684573272\t\n",
        "lambda: 0.41843213030761\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00027761562453632\t\n",
        "lambda: 0.41843250799629\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00027313468594683\t\n",
        "lambda: 0.41843287338337\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00026882377965355\t\n",
        "lambda: 0.41843322713446\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00026467339365724\t\n",
        "lambda: 0.4184335698668\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0002606746907513\t\n",
        "lambda: 0.41843390215359\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00025681945092116\t\n",
        "lambda: 0.41843422452778\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00025310001989604\t\n",
        "lambda: 0.41843453748557\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00024950926239134\t\n",
        "lambda: 0.41843484148952\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00024604051980922\t\n",
        "lambda: 0.41843513697133\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00024268757219024\t\n",
        "lambda: 0.41843542433441\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00023944460349321\t\n",
        "lambda: 0.41843570395614\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00023630617017331\t\n",
        "lambda: 0.41843597618994\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00023326717249017\t\n",
        "lambda: 0.41843624136713\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00023032282856191\t\n",
        "lambda: 0.41843649979868\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00022746865053266\t\n",
        "lambda: 0.41843675177673\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00022470042293999\t\n",
        "lambda: 0.41843699757599\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00022201418294208\t\n",
        "lambda: 0.41843723745507\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00021940620209028\t\n",
        "lambda: 0.41843747165758\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0002168729698072\t\n",
        "lambda: 0.4184377004133\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00021441117815125\t\n",
        "lambda: 0.41843792393907\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0002120177077956\t\n",
        "lambda: 0.41843814243977\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00020968961516488\t\n",
        "lambda: 0.41843835610909\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00020742412066454\t\n",
        "lambda: 0.41843856513031\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00020521859764774\t\n",
        "lambda: 0.41843876967702\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00020307056254033\t\n",
        "lambda: 0.41843896991372\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00020097766539\t\n",
        "lambda: 0.41843916599646\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00019893768132878\t\n",
        "lambda: 0.41843935807335\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00019694850265688\t\n",
        "lambda: 0.41843954628508\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00019500813146361\t\n",
        "lambda: 0.4184397307654\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0001931146727892\t\n",
        "lambda: 0.41843991164153\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00019126632831995\t\n",
        "lambda: 0.41844008903458\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018946139047404\t\n",
        "lambda: 0.41844026305991\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018769823696107\t\n",
        "lambda: 0.41844043382746\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018597532564306\t\n",
        "lambda: 0.41844060144215\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018429118989482\t\n",
        "lambda: 0.41844076600403\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018264443409089\t\n",
        "lambda: 0.41844092760873\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00018103372950993\t\n",
        "lambda: 0.41844108634757\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017945781052669\t\n",
        "lambda: 0.41844124230787\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017791547101198\t\n",
        "lambda: 0.41844139557322\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017640556088649\t\n",
        "lambda: 0.41844154622358\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017492698311248\t\n",
        "lambda: 0.41844169433555\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017347869067782\t\n",
        "lambda: 0.41844183998255\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017205968384657\t\n",
        "lambda: 0.41844198323495\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00017066900760358\t\n",
        "lambda: 0.41844212416028\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0001693057492204\t\n",
        "lambda: 0.41844226282335\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016796903598022\t\n",
        "lambda: 0.41844239928638\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016665803307592\t\n",
        "lambda: 0.41844253360918\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016537194157313\t\n",
        "lambda: 0.41844266584921\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016410999653585\t\n",
        "lambda: 0.41844279606175\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016287146531301\t\n",
        "lambda: 0.41844292429998\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016165564576801\t\n",
        "lambda: 0.41844305061509\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00016046186484257\t\n",
        "lambda: 0.41844317505638\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015928947696152\t\n",
        "lambda: 0.41844329767134\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.0001581378627574\t\n",
        "lambda: 0.41844341850575\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015700642766045\t\n",
        "lambda: 0.41844353760377\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015589460073605\t\n",
        "lambda: 0.41844365500795\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015480183352538\t\n",
        "lambda: 0.4184437707594\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015372759886849\t\n",
        "lambda: 0.4184438848978\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015267138998467\t\n",
        "lambda: 0.41844399746146\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015163271939957\t\n",
        "lambda: 0.41844410848742\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "|Hv-lambda v|: 0.00015061111806157\t\n",
        "lambda: 0.41844421801142\t\n",
        "min eigenvalue of hessian: 2.3193220577311e-05\t\n",
        "did converge: \t\n",
        "false\t\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function lanczosAE(inputs, param, delta, filepath, modelpath) \n",
      "    local maxIter = 50\n",
      "    local acc_threshold = .2\n",
      "    local criterion = nn.MSECriterion()\n",
      "    --criterion.sizeAverage = false\n",
      "    local model_a  = nn.Sequential ()                                                                                                                                            \n",
      "    model_a:add(dofile(modelFile))\n",
      "    --model_a:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local model_b = nn.Sequential()\n",
      "    model_b:add(dofile(modelFile))\n",
      "    --model_b:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local param_new_a, gradParam_eps_a = model_a:getParameters() \n",
      "    local param_new_b, gradParam_eps_b = model_b:getParameters() \n",
      "    -- in order to reflect loading a new parameter set\n",
      "    \n",
      "    local T = torch.Tensor(maxIter,maxIter):fill(0)-- initialize the tri-diagonal matrix T with zeros\n",
      "    dim = param:size(1)\n",
      "    local Vt = torch.Tensor(maxIter, dim):fill(0)-- initialize the Krylov matrix with zeros\n",
      "    -- initialize:\n",
      "    local v = torch.randn(param:size()) \n",
      "    v = v/torch.norm(v)\n",
      "    local v_old = 0\n",
      "    local beta = 0;\n",
      "    \n",
      "    for iter =1, maxIter do\n",
      "        Vt[iter] = v\n",
      "        \n",
      "        epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(v)\n",
      "        param_new_a:copy(param + v * epsilon)\n",
      "        param_new_b:copy(param - v * epsilon)\n",
      "\n",
      "        --reset gradients\n",
      "        gradParam_eps_a:zero()\n",
      "        gradParam_eps_b:zero()\n",
      "        \n",
      "\n",
      "        --feedforward and backpropagation\n",
      "        local outputs = model_a:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "  \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_a:div(inputs:size(1))\n",
      "        \n",
      "        local outputs = model_b:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "    \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_b:div(inputs:size(1))\n",
      "\n",
      "        local Hv = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "        local ww = Hv -- omega prime\n",
      "        local alpha = torch.dot(ww, v)\n",
      "        local w = ww - v*alpha - v_old*beta\n",
      "        ww = nil \n",
      "        Hv = nil\n",
      "        beta = torch.norm(w)\n",
      "        v_old = v:clone()\n",
      "        v = w / beta\n",
      "        w = nil\n",
      "        T[iter][iter] = alpha\n",
      "        if iter<maxIter then\n",
      "            T[iter][iter+1] = beta\n",
      "            T[iter+1][iter] = beta \n",
      "        end    \n",
      "    end\n",
      "\n",
      "    -- find eigenvalues and eigenvectors of T\n",
      "    lambdas, V_T = torch.symeig(T, 'V') -- maximal eigenvalue of T and the corresponding eigenvector\n",
      "    local yy, i = torch.sort(torch.abs(lambdas))\n",
      "    lambda = yy[maxIter]\n",
      "    V_TT = V_T:t()\n",
      "    v = V_TT[i[maxIter]]\n",
      "    --------------------------------------------------\n",
      "    -- get eigenvector of H\n",
      "    V = Vt:t() -- now V is the Krylov matrix\n",
      "    v = torch.mv(V, v)\n",
      "    v = v / torch.norm(v)\n",
      "    --compute Hv\n",
      "    param_new_a:copy(param + v * epsilon)\n",
      "    param_new_b:copy(param - v * epsilon)\n",
      "\n",
      "    --reset gradients\n",
      "    gradParam_eps_a:zero()\n",
      "    gradParam_eps_b:zero()\n",
      "\n",
      "    local epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(v)\n",
      "\n",
      "    --feedforward and backpropagation\n",
      "    local outputs = model_a:forward(inputs)\n",
      "    local f = criterion:forward(outputs, inputs)\n",
      "    local df_do = criterion:backward(outputs, inputs)\n",
      "    model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "\n",
      "    --f = f/inputs:size(1)\n",
      "    --gradParam_eps_a:div(inputs:size(1))\n",
      "\n",
      "    local outputs = model_b:forward(inputs)\n",
      "    local f = criterion:forward(outputs, inputs)\n",
      "    local df_do = criterion:backward(outputs, inputs)\n",
      "    model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "\n",
      "    --f = f/inputs:size(1)\n",
      "    --gradParam_eps_b:div(inputs:size(1))\n",
      "\n",
      "    local Hv = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "    local diff = torch.norm(Hv - v*lambda)\n",
      "    print('|Hv-lambda v|: '..diff) -- TODO: comment this out\n",
      "    converged = torch.abs(lambda) > diff and diff<acc_threshold\n",
      "    return lambda, v, converged\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maxEigValH, v, converged = lanczosAE(inputs,params, 1e-7, _, _) \n",
      "print('max eigenvalue of hessian: '..maxEigValH)\n",
      "print('did converge: ')\n",
      "print(converged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "|Hv-lambda v|: 1.7724699707034e-08\t\n",
        "max eigenvalue of hessian: 0.41846741677256\t\n",
        "did converge: \t\n",
        "true\t\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function negativeLanczosAE(inputs, param, delta, filepath, modelpath, maxEigValH) \n",
      "    local maxIter = 100\n",
      "    local acc_threshold = .2\n",
      "    local criterion = nn.MSECriterion()\n",
      "    --criterion.sizeAverage = false\n",
      "    local model_a  = nn.Sequential ()                                                                                                                                            \n",
      "    model_a:add(dofile(modelFile))\n",
      "    --model_a:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local model_b = nn.Sequential()\n",
      "    model_b:add(dofile(modelFile))\n",
      "    --model_b:add(dofile(filepath .. modelpath))\n",
      "\n",
      "    local param_new_a, gradParam_eps_a = model_a:getParameters() \n",
      "    local param_new_b, gradParam_eps_b = model_b:getParameters() \n",
      "    -- in order to reflect loading a new parameter set\n",
      "    \n",
      "    local T = torch.Tensor(maxIter,maxIter):fill(0)-- initialize the tri-diagonal matrix T with zeros\n",
      "    dim = param:size(1)\n",
      "    local Vt = torch.Tensor(maxIter, dim):fill(0)-- initialize the Krylov matrix with zeros\n",
      "    -- initialize:\n",
      "    local v = torch.randn(param:size()) \n",
      "    v = v/torch.norm(v)\n",
      "    local v_old = 0\n",
      "    local beta = 0;\n",
      "    \n",
      "    for iter =1, maxIter do\n",
      "        Vt[iter] = v\n",
      "        \n",
      "        epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(v)\n",
      "        param_new_a:copy(param + v * epsilon)\n",
      "        param_new_b:copy(param - v * epsilon)\n",
      "\n",
      "        --reset gradients\n",
      "        gradParam_eps_a:zero()\n",
      "        gradParam_eps_b:zero()\n",
      "        \n",
      "\n",
      "        --feedforward and backpropagation\n",
      "        local outputs = model_a:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "  \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_a:div(inputs:size(1))\n",
      "        \n",
      "        local outputs = model_b:forward(inputs)\n",
      "        local f = criterion:forward(outputs, inputs)\n",
      "        local df_do = criterion:backward(outputs, inputs)\n",
      "        model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "    \n",
      "        --f = f/inputs:size(1)\n",
      "        --gradParam_eps_b:div(inputs:size(1))\n",
      "\n",
      "        local Hv = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "        local Mv = v*maxEigValH - Hv\n",
      "        Hv = nil\n",
      "        local ww = Mv -- omega prime\n",
      "        local alpha = torch.dot(ww, v)\n",
      "        local w = ww - v*alpha - v_old*beta\n",
      "        ww = nil \n",
      "        Hv = nil\n",
      "        beta = torch.norm(w)\n",
      "        v_old = v:clone()\n",
      "        v = w / beta\n",
      "        w = nil\n",
      "        T[iter][iter] = alpha\n",
      "        if iter<maxIter then\n",
      "            T[iter][iter+1] = beta\n",
      "            T[iter+1][iter] = beta \n",
      "        end    \n",
      "    end\n",
      "\n",
      "    -- find eigenvalues and eigenvectors of T\n",
      "    lambdas, V_T = torch.symeig(T, 'V') -- maximal eigenvalue of T and the corresponding eigenvector\n",
      "    local yy, i = torch.sort(torch.abs(lambdas))\n",
      "    lambda = yy[maxIter]\n",
      "    V_TT = V_T:t()\n",
      "    v = V_TT[i[maxIter]]\n",
      "    --------------------------------------------------\n",
      "    -- get eigenvector of H\n",
      "    V = Vt:t() -- now V is the Krylov matrix\n",
      "    v = torch.mv(V, v)\n",
      "    v = v / torch.norm(v)\n",
      "    --compute Hv\n",
      "    param_new_a:copy(param + v * epsilon)\n",
      "    param_new_b:copy(param - v * epsilon)\n",
      "\n",
      "    --reset gradients\n",
      "    gradParam_eps_a:zero()\n",
      "    gradParam_eps_b:zero()\n",
      "\n",
      "    local epsilon = 2*torch.sqrt(1e-15)*(1 + torch.norm(param))/torch.norm(v)\n",
      "\n",
      "    --feedforward and backpropagation\n",
      "    local outputs = model_a:forward(inputs)\n",
      "    local f = criterion:forward(outputs, inputs)\n",
      "    local df_do = criterion:backward(outputs, inputs)\n",
      "    model_a:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "\n",
      "    --f = f/inputs:size(1)\n",
      "    --gradParam_eps_a:div(inputs:size(1))\n",
      "\n",
      "    local outputs = model_b:forward(inputs)\n",
      "    local f = criterion:forward(outputs, inputs)\n",
      "    local df_do = criterion:backward(outputs, inputs)\n",
      "    model_b:backward(inputs, df_do) --gradParams_eps should be updated here \n",
      "\n",
      "    --f = f/inputs:size(1)\n",
      "    --gradParam_eps_b:div(inputs:size(1))\n",
      "\n",
      "    local Hv = (gradParam_eps_a - gradParam_eps_b) / (2*epsilon)\n",
      "    local Mv = v*maxEigValH - Hv\n",
      "    \n",
      "    minEigValH = maxEigValH - lambda\n",
      "    local diff_M = torch.norm(v*lambda - Mv)\n",
      "    local diff_H = torch.norm(v*minEigValH - Hv)\n",
      "    \n",
      "    --print(diff_M) -- TODO: comment this out\n",
      "    print('|Hv-lambda v|: '..diff_H) -- TODO: comment this out\n",
      "    converged = torch.abs(minEigValH) > diff_H and torch.abs(lambda) > diff_M and diff_H < acc_threshold\n",
      "    return minEigValH, v, converged\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minEigValH, v, converged = negativeLanczosAE(inputs,params, 1e-7, _, _, maxEigValH) \n",
      "print('min eigenvalue of hessian: '..minEigValH)\n",
      "print('did converge: ')\n",
      "print(converged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "|Hv-lambda v|: 1.7794392602333e-05\t\n",
        "min eigenvalue of hessian: 7.6222204964393e-07\t\n",
        "did converge: \t\n",
        "false\t\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}